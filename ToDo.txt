1. Add chatMemory (//BIG ToDo\\)
2. Add logging (kinda done?) - Add a database (SQLite/Grafana ?) for the logs (kinda done)
	[Remove query, query_token_len (its always gonna be 768]
3. Apply profiling to see bottlenecks (DONE)
4. t-Sne embeddings visualizations ? 
5. Add options for Language Models, Retrieval DBs (DONE) 
   and embedding models	(Kinda done[embedding left])
6. Remove deprecated dependecies
7. Cache heavy functions (Kinda done)
8. Add pdf Annotations (kinda done) 
9. Bring relevant graphics/images
10. Stream LM responses with a generator (DONE)
11. Make the UI/UX better
12. Get Data/Rent GPU for fine-tuning 
13. Maybe try some other parser or create your own instead of using
PyPDFLoader (it gives good performance though)
14. Add fine-tuning
15. Add option for both Ollama and API-Called LLM inference